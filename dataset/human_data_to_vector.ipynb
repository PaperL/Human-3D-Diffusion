{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mmhuman3d: 0.10.0\n"
     ]
    }
   ],
   "source": [
    "from mmhuman3d.data.data_structures.human_data import HumanData\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm\n",
    "import mmhuman3d\n",
    "print('mmhuman3d:', mmhuman3d.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Find 25 npz file(s).\n"
     ]
    }
   ],
   "source": [
    "dataset_folder_path = Path('/home/paperlane/workspace/@Python/dataset')\n",
    "assert dataset_folder_path.is_dir()\n",
    "assert dataset_folder_path.exists()\n",
    "npz_file_paths = list(dataset_folder_path.rglob('*.npz'))\n",
    "assert len(npz_file_paths) > 0\n",
    "print('Find', len(npz_file_paths), 'npz file(s).')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_19206/1949276781.py:2: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for npz_file_path in tqdm(npz_file_paths):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acc1f8c95d1f4b2687718ea2f7a21a18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [17], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtqdm\u001b[39;00m \u001b[39mimport\u001b[39;00m tqdm_notebook \u001b[39mas\u001b[39;00m tqdm\n\u001b[1;32m      2\u001b[0m \u001b[39mfor\u001b[39;00m npz_file_path \u001b[39min\u001b[39;00m tqdm(npz_file_paths):\n\u001b[1;32m      3\u001b[0m     \u001b[39m# print(str(npz_file_path))\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m     dat \u001b[39m=\u001b[39m HumanData\u001b[39m.\u001b[39;49mfromfile(\u001b[39mstr\u001b[39;49m(npz_file_path))\n\u001b[1;32m      5\u001b[0m     \u001b[39m# print('Keys:', dat.keys())\u001b[39;00m\n\u001b[1;32m      6\u001b[0m     n \u001b[39m=\u001b[39m dat[\u001b[39m'\u001b[39m\u001b[39mperson_id\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]\n",
      "File \u001b[0;32m~/workspace/@Python/Human-3D-Diffusion/mmhuman3d/mmhuman3d/data/data_structures/human_data.py:149\u001b[0m, in \u001b[0;36mHumanData.fromfile\u001b[0;34m(cls, npz_path)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[39m\"\"\"Construct a HumanData instance from an npz file.\u001b[39;00m\n\u001b[1;32m    139\u001b[0m \n\u001b[1;32m    140\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[39m        A HumanData instance load from file.\u001b[39;00m\n\u001b[1;32m    147\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    148\u001b[0m ret_human_data \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39m()\n\u001b[0;32m--> 149\u001b[0m ret_human_data\u001b[39m.\u001b[39;49mload(npz_path)\n\u001b[1;32m    150\u001b[0m \u001b[39mreturn\u001b[39;00m ret_human_data\n",
      "File \u001b[0;32m~/workspace/@Python/Human-3D-Diffusion/mmhuman3d/mmhuman3d/data/data_structures/human_data.py:218\u001b[0m, in \u001b[0;36mHumanData.load\u001b[0;34m(self, npz_path)\u001b[0m\n\u001b[1;32m    216\u001b[0m supported_keys \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39mSUPPORTED_KEYS\n\u001b[1;32m    217\u001b[0m \u001b[39mwith\u001b[39;00m np\u001b[39m.\u001b[39mload(npz_path, allow_pickle\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m) \u001b[39mas\u001b[39;00m npz_file:\n\u001b[0;32m--> 218\u001b[0m     tmp_data_dict \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39;49m(npz_file)\n\u001b[1;32m    219\u001b[0m     \u001b[39mfor\u001b[39;00m key, value \u001b[39min\u001b[39;00m \u001b[39mlist\u001b[39m(tmp_data_dict\u001b[39m.\u001b[39mitems()):\n\u001b[1;32m    220\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(value, np\u001b[39m.\u001b[39mndarray) \u001b[39mand\u001b[39;00m\\\n\u001b[1;32m    221\u001b[0m                 \u001b[39mlen\u001b[39m(value\u001b[39m.\u001b[39mshape) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    222\u001b[0m             \u001b[39m# value is not an ndarray before dump\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/numpy/lib/npyio.py:245\u001b[0m, in \u001b[0;36mNpzFile.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    243\u001b[0m \u001b[39mif\u001b[39;00m magic \u001b[39m==\u001b[39m \u001b[39mformat\u001b[39m\u001b[39m.\u001b[39mMAGIC_PREFIX:\n\u001b[1;32m    244\u001b[0m     \u001b[39mbytes\u001b[39m \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mzip\u001b[39m.\u001b[39mopen(key)\n\u001b[0;32m--> 245\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mformat\u001b[39;49m\u001b[39m.\u001b[39;49mread_array(\u001b[39mbytes\u001b[39;49m,\n\u001b[1;32m    246\u001b[0m                              allow_pickle\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mallow_pickle,\n\u001b[1;32m    247\u001b[0m                              pickle_kwargs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpickle_kwargs)\n\u001b[1;32m    248\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    249\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mzip\u001b[39m.\u001b[39mread(key)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/numpy/lib/format.py:777\u001b[0m, in \u001b[0;36mread_array\u001b[0;34m(fp, allow_pickle, pickle_kwargs)\u001b[0m\n\u001b[1;32m    775\u001b[0m             read_count \u001b[39m=\u001b[39m \u001b[39mmin\u001b[39m(max_read_count, count \u001b[39m-\u001b[39m i)\n\u001b[1;32m    776\u001b[0m             read_size \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(read_count \u001b[39m*\u001b[39m dtype\u001b[39m.\u001b[39mitemsize)\n\u001b[0;32m--> 777\u001b[0m             data \u001b[39m=\u001b[39m _read_bytes(fp, read_size, \u001b[39m\"\u001b[39;49m\u001b[39marray data\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m    778\u001b[0m             array[i:i\u001b[39m+\u001b[39mread_count] \u001b[39m=\u001b[39m numpy\u001b[39m.\u001b[39mfrombuffer(data, dtype\u001b[39m=\u001b[39mdtype,\n\u001b[1;32m    779\u001b[0m                                                      count\u001b[39m=\u001b[39mread_count)\n\u001b[1;32m    781\u001b[0m \u001b[39mif\u001b[39;00m fortran_order:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/numpy/lib/format.py:906\u001b[0m, in \u001b[0;36m_read_bytes\u001b[0;34m(fp, size, error_template)\u001b[0m\n\u001b[1;32m    901\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    902\u001b[0m     \u001b[39m# io files (default in python3) return None or raise on\u001b[39;00m\n\u001b[1;32m    903\u001b[0m     \u001b[39m# would-block, python2 file will truncate, probably nothing can be\u001b[39;00m\n\u001b[1;32m    904\u001b[0m     \u001b[39m# done about that.  note that regular files can't be non-blocking\u001b[39;00m\n\u001b[1;32m    905\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 906\u001b[0m         r \u001b[39m=\u001b[39m fp\u001b[39m.\u001b[39;49mread(size \u001b[39m-\u001b[39;49m \u001b[39mlen\u001b[39;49m(data))\n\u001b[1;32m    907\u001b[0m         data \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m r\n\u001b[1;32m    908\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(r) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m \u001b[39mor\u001b[39;00m \u001b[39mlen\u001b[39m(data) \u001b[39m==\u001b[39m size:\n",
      "File \u001b[0;32m~/toolchain/anaconda3/envs/mmlab/lib/python3.8/zipfile.py:940\u001b[0m, in \u001b[0;36mZipExtFile.read\u001b[0;34m(self, n)\u001b[0m\n\u001b[1;32m    938\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_offset \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m    939\u001b[0m \u001b[39mwhile\u001b[39;00m n \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_eof:\n\u001b[0;32m--> 940\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_read1(n)\n\u001b[1;32m    941\u001b[0m     \u001b[39mif\u001b[39;00m n \u001b[39m<\u001b[39m \u001b[39mlen\u001b[39m(data):\n\u001b[1;32m    942\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_readbuffer \u001b[39m=\u001b[39m data\n",
      "File \u001b[0;32m~/toolchain/anaconda3/envs/mmlab/lib/python3.8/zipfile.py:1016\u001b[0m, in \u001b[0;36mZipExtFile._read1\u001b[0;34m(self, n)\u001b[0m\n\u001b[1;32m   1014\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compress_type \u001b[39m==\u001b[39m ZIP_DEFLATED:\n\u001b[1;32m   1015\u001b[0m     n \u001b[39m=\u001b[39m \u001b[39mmax\u001b[39m(n, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mMIN_READ_SIZE)\n\u001b[0;32m-> 1016\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_decompressor\u001b[39m.\u001b[39;49mdecompress(data, n)\n\u001b[1;32m   1017\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_eof \u001b[39m=\u001b[39m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_decompressor\u001b[39m.\u001b[39meof \u001b[39mor\u001b[39;00m\n\u001b[1;32m   1018\u001b[0m                  \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compress_left \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m\n\u001b[1;32m   1019\u001b[0m                  \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_decompressor\u001b[39m.\u001b[39munconsumed_tail)\n\u001b[1;32m   1020\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_eof:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for npz_file_path in tqdm(npz_file_paths):\n",
    "    # print(str(npz_file_path))\n",
    "    dat = HumanData.fromfile(str(npz_file_path))\n",
    "    # print('Keys:', dat.keys())\n",
    "    n = dat['person_id'].shape[0]\n",
    "    # print('Person Num:', n)\n",
    "    # print('SMPL Data Type:', *((x, y.shape)\n",
    "    #       for x, y in dat['smpl'].items()), sep='\\n')\n",
    "    ret = np.empty([n, 0])\n",
    "    for smpl_type in dat['smpl'].keys():\n",
    "        np_array = dat['smpl'][smpl_type]\n",
    "        np_array = np_array.reshape(n, -1)\n",
    "        ret = np.concatenate((ret, np_array), axis=1)\n",
    "    # print('Result np.array.shape:', ret.shape)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('mmlab')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f0fef1919fcae890cfc7ed1f5cd0c88e2a1319c25a51740bfb44a8194939caaf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
